# ğŸ§ª Tests del Backend - GuÃ­a Zen de Testing

> *"Un test bien escrito es como un koan zen: claro, directo y revelador."*

## ğŸ“– FilosofÃ­a de Testing

Estos tests siguen los principios del Zen de Python:

### ğŸ§˜ Principios Aplicados

1. **ExplÃ­cito es mejor que implÃ­cito**
   - Nombres de tests descriptivos que documentan el comportamiento
   - Asserts claros con mensajes especÃ­ficos
   - No hay "magic numbers" ni valores ambiguos

2. **Simple es mejor que complejo**
   - Un test = una responsabilidad
   - Tests fÃ¡ciles de leer y entender
   - Fixtures reutilizables para reducir duplicaciÃ³n

3. **Plano es mejor que anidado**
   - Tests organizados en clases por funcionalidad
   - Early returns en validaciones
   - Fixtures independientes

4. **Los errores nunca deberÃ­an pasar silenciosamente**
   - Todos los casos de error tienen tests
   - Tests de validaciones explÃ­citas
   - Tests de autenticaciÃ³n/autorizaciÃ³n

---

## ğŸ“‚ Estructura de Tests

```
tests/
â”œâ”€â”€ __init__.py           # DocumentaciÃ³n de la suite
â”œâ”€â”€ conftest.py           # Fixtures compartidas
â”œâ”€â”€ README.md            # Esta guÃ­a
â”‚
â”œâ”€â”€ unit/                # Tests unitarios
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_security.py # Tests de funciones de seguridad
â”‚
â”œâ”€â”€ routers/             # Tests de endpoints
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_auth.py     # Tests de autenticaciÃ³n
â”‚   â”œâ”€â”€ test_categorias.py
â”‚   â”œâ”€â”€ test_habitos.py
â”‚   â””â”€â”€ test_registros.py
â”‚
â””â”€â”€ integration/         # Tests end-to-end
    â””â”€â”€ __init__.py
```

---

## ğŸš€ EjecuciÃ³n de Tests

### Instalar Dependencias de Testing

```bash
# Con uv (recomendado)
cd backend
uv sync --dev

# O con pip
pip install -e ".[dev]"
```

### Ejecutar Todos los Tests

```bash
# Desde el directorio backend/
pytest

# Con output verbose
pytest -v

# Con cobertura
pytest --cov=app --cov-report=html

# Solo tests de un mÃ³dulo especÃ­fico
pytest tests/routers/test_auth.py

# Solo tests que coincidan con un patrÃ³n
pytest -k "test_login"
```

### Ejecutar Tests con Diferentes Niveles de Detalle

```bash
# MÃ­nimo (solo puntos)
pytest

# Normal (nombres de archivos)
pytest -v

# Detallado (nombres completos de tests)
pytest -vv

# Con print statements
pytest -s

# Detener en el primer fallo
pytest -x

# Mostrar tests mÃ¡s lentos
pytest --durations=10
```

---

## ğŸ¯ Convenciones de Naming

### Nombres de Clases de Test

```python
class TestGetHabitos:      # Agrupa tests del endpoint GET /habitos
class TestCreateHabito:    # Agrupa tests del endpoint POST /habitos
class TestUpdateHabito:    # Agrupa tests del endpoint PUT /habitos
```

### Nombres de Funciones de Test

Formato: `test_<accion>_<condicion>_<resultado>`

```python
test_login_success()                    # Happy path
test_login_wrong_password_fails()       # Caso de error
test_get_habito_requires_auth()         # ValidaciÃ³n de autenticaciÃ³n
test_create_habito_invalid_data_fails() # ValidaciÃ³n de datos
```

---

## ğŸ”§ Fixtures Disponibles

### Fixtures de Base de Datos

- `test_engine`: Engine SQLAlchemy con BD en memoria
- `test_db_session`: SesiÃ³n de BD para cada test (con rollback automÃ¡tico)
- `test_client`: Cliente HTTP asÃ­ncrono con BD de test

### Fixtures de AutenticaciÃ³n

- `test_user`: Usuario de prueba estÃ¡ndar
- `test_user_with_future`: Usuario con `ver_futuro=True`
- `auth_token`: Token JWT para el usuario de prueba
- `auth_headers`: Headers con `Authorization: Bearer <token>`

### Fixtures de Datos

- `test_categoria`: CategorÃ­a de prueba ("Salud")

### Ejemplo de Uso

```python
@pytest.mark.asyncio
async def test_mi_endpoint(
    test_client: AsyncClient,
    test_user: usuario,
    auth_headers: dict
):
    """Test: DescripciÃ³n clara del comportamiento esperado."""
    response = await test_client.get(
        "/mi-endpoint",
        headers=auth_headers
    )

    assert response.status_code == 200
    data = response.json()
    assert data["user_id"] == test_user.id
```

---

## âœ… Checklist de Test Completo

Para cada endpoint, asegÃºrate de tener tests para:

### Happy Path
- [ ] OperaciÃ³n exitosa con datos vÃ¡lidos
- [ ] Retorna el status code correcto
- [ ] Retorna los datos esperados en el formato correcto

### AutenticaciÃ³n y AutorizaciÃ³n
- [ ] Requiere autenticaciÃ³n cuando corresponde
- [ ] Rechaza tokens invÃ¡lidos
- [ ] Solo permite acceso a recursos propios

### ValidaciÃ³n de Datos
- [ ] Rechaza datos faltantes
- [ ] Rechaza datos con formato invÃ¡lido
- [ ] Valida lÃ­mites (min/max length, valores)

### Casos Edge
- [ ] Recursos no encontrados (404)
- [ ] Datos duplicados
- [ ] Operaciones idempotentes

### Errores
- [ ] Manejo apropiado de errores de BD
- [ ] Mensajes de error claros y especÃ­ficos

---

## ğŸ› Debugging de Tests

### Test EspecÃ­fico Falla

```bash
# Ejecutar solo ese test con output verbose
pytest tests/routers/test_auth.py::TestLogin::test_login_success -vv

# Con print statements
pytest tests/routers/test_auth.py::TestLogin::test_login_success -s

# Con debugger
pytest tests/routers/test_auth.py::TestLogin::test_login_success --pdb
```

### Todos los Tests de un MÃ³dulo Fallan

```bash
# Ver stack traces completos
pytest tests/routers/test_auth.py -vv --tb=long

# Ver solo el primer fallo
pytest tests/routers/test_auth.py -x
```

### Base de Datos en Tests

```python
# Activar logging de SQL en conftest.py
engine = create_async_engine(
    TEST_DATABASE_URL,
    echo=True  # ğŸ” Muestra todas las queries SQL
)
```

---

## ğŸ“Š Cobertura de Tests

### Generar Reporte de Cobertura

```bash
# Generar reporte HTML
pytest --cov=app --cov-report=html

# Abrir reporte
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
```

### Objetivo de Cobertura

- **CrÃ­tico (100%):** `security.py`, `auth.py`
- **Alto (>80%):** Routers principales
- **Medio (>60%):** Utilidades y helpers
- **Bajo:** ConfiguraciÃ³n, main.py

---

## ğŸ§˜ Mejores PrÃ¡cticas Zen

### 1. Un Test = Una Responsabilidad

âŒ **Mal:**
```python
def test_create_and_update_user():
    # Crea usuario
    # Actualiza usuario
    # Elimina usuario
    # âŒ Hace demasiado
```

âœ… **Bien:**
```python
def test_create_user_success():
    # Solo crea usuario

def test_update_user_success():
    # Solo actualiza usuario
```

### 2. Nombres Descriptivos

âŒ **Mal:**
```python
def test_1():
def test_error():
def test_usuario():
```

âœ… **Bien:**
```python
def test_login_wrong_password_fails():
def test_create_user_duplicate_email_fails():
def test_get_habito_requires_authentication():
```

### 3. Asserts ExplÃ­citos

âŒ **Mal:**
```python
assert response.status_code  # Â¿QuÃ© esperamos?
assert data  # Â¿QuÃ© debe contener?
```

âœ… **Bien:**
```python
assert response.status_code == 201
assert "access_token" in data
assert data["user"]["email"] == "test@example.com"
```

### 4. Fixtures Claras

âŒ **Mal:**
```python
@pytest.fixture
def user():
    # Â¿QuÃ© tipo de usuario?
    # Â¿Con quÃ© datos?
```

âœ… **Bien:**
```python
@pytest_asyncio.fixture
async def test_user(test_db_session: AsyncSession) -> usuario:
    """
    Crea un usuario de prueba en la base de datos.

    Returns:
        usuario con email=test@example.com y ver_futuro=False
    """
```

---

## ğŸ“š Referencias

- [pytest Documentation](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [FastAPI Testing](https://fastapi.tiangolo.com/tutorial/testing/)
- [The Zen of Python (PEP 20)](https://www.python.org/dev/peps/pep-0020/)

---

ğŸ§˜ **"Un test que falla es un maestro. Un test que pasa es un alumno. Una suite completa es la iluminaciÃ³n."** - Maestro Zen

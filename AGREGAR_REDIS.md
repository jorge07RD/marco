# Gu√≠a de Integraci√≥n de Redis en Marco

## Resumen Ejecutivo

**Nivel de Complejidad:** MODERADO (2-4 horas de desarrollo + 1-2 horas de testing)

**Beneficio Principal:** Optimizaci√≥n significativa de endpoints de an√°lisis que ejecutan m√∫ltiples queries complejas.

---

## Estado Actual del Proyecto

### Backend
- **Framework:** FastAPI con AsyncIO
- **Base de datos:** SQLite con SQLAlchemy AsyncIO
- **Autenticaci√≥n:** JWT (tokens de 7 d√≠as)
- **Cach√© actual:** Solo `@lru_cache` para configuraci√≥n (`config.py:33`)

### Arquitectura Preparada
‚úÖ Ya usa AsyncIO completo ‚Üí Compatible con `aioredis`
‚úÖ Pattern de inyecci√≥n de dependencias ‚Üí F√°cil agregar Redis como dependencia
‚úÖ C√≥digo organizado por routers ‚Üí Puntos claros de integraci√≥n

---

## Endpoints Prioritarios para Cach√©

| Endpoint | Archivo | L√≠nea | Beneficio | TTL Sugerido |
|----------|---------|-------|-----------|--------------|
| `GET /api/analisis/rendimiento` | `routers/analisis.py` | 23 | üî• MUY ALTO | 1 hora |
| `GET /api/analisis/cumplimiento` | `routers/analisis.py` | 89 | üî• MUY ALTO | 1 hora |
| `GET /api/categorias/` | `routers/categorias.py` | 12 | üü° MEDIO | 24 horas |
| `GET /api/habitos/` | `routers/habitos.py` | 17 | üü¢ BAJO | 15 minutos |

**Raz√≥n:** Los endpoints de an√°lisis ejecutan m√∫ltiples queries para calcular m√©tricas de rendimiento y cumplimiento, lo que los hace candidatos perfectos para cach√©.

---

## Plan de Implementaci√≥n

### Paso 1: Instalar Redis

#### Opci√≥n A: Docker (Recomendado para desarrollo)
```bash
docker run -d \
  --name redis-marco \
  -p 6379:6379 \
  redis:7-alpine
```

#### Opci√≥n B: Instalaci√≥n local
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install redis-server

# macOS
brew install redis

# Iniciar servicio
redis-server
```

#### Verificar instalaci√≥n
```bash
redis-cli ping
# Debe responder: PONG
```

---

### Paso 2: Agregar Dependencia de Python

Editar `backend/pyproject.toml`:

```toml
[project]
dependencies = [
    # ... dependencias existentes ...
    "redis>=5.0.0",
]
```

Instalar:
```bash
cd backend
uv sync
```

---

### Paso 3: Configuraci√≥n de Redis

#### 3.1. Actualizar `backend/app/config.py`

A√±adir despu√©s de la l√≠nea 15 (despu√©s de `DATABASE_URL`):

```python
class Settings(BaseSettings):
    # ... campos existentes ...

    # Redis
    REDIS_URL: str = "redis://localhost:6379/0"
    REDIS_TTL_DEFAULT: int = 3600  # 1 hora en segundos
    REDIS_TTL_ANALYTICS: int = 3600  # 1 hora para an√°lisis
    REDIS_TTL_CATEGORIES: int = 86400  # 24 horas para categor√≠as
    REDIS_TTL_HABITS: int = 900  # 15 minutos para h√°bitos
    REDIS_ENABLED: bool = True  # Permitir desactivar en desarrollo
```

#### 3.2. Actualizar `backend/.env`

A√±adir al final del archivo:

```bash
# REDIS
REDIS_URL=redis://localhost:6379/0
REDIS_TTL_DEFAULT=3600
REDIS_TTL_ANALYTICS=3600
REDIS_TTL_CATEGORIES=86400
REDIS_TTL_HABITS=900
REDIS_ENABLED=true
```

---

### Paso 4: Crear M√≥dulo de Cach√©

Crear nuevo archivo `backend/app/cache.py`:

```python
"""
Sistema de cach√© con Redis para optimizar consultas frecuentes.
"""
import json
import hashlib
from typing import Any, Optional
from functools import wraps
import redis.asyncio as redis
from fastapi import Request

from .config import get_settings

settings = get_settings()

# Cliente Redis global (se inicializa en startup)
redis_client: Optional[redis.Redis] = None


async def init_redis():
    """Inicializar conexi√≥n a Redis."""
    global redis_client
    if settings.REDIS_ENABLED:
        redis_client = redis.from_url(
            settings.REDIS_URL,
            encoding="utf-8",
            decode_responses=True
        )
        try:
            await redis_client.ping()
            print("‚úÖ Redis conectado exitosamente")
        except Exception as e:
            print(f"‚ö†Ô∏è  Redis no disponible: {e}")
            redis_client = None


async def close_redis():
    """Cerrar conexi√≥n a Redis."""
    global redis_client
    if redis_client:
        await redis_client.close()
        print("Redis desconectado")


def generate_cache_key(prefix: str, *args, **kwargs) -> str:
    """
    Generar clave de cach√© √∫nica basada en par√°metros.

    Args:
        prefix: Prefijo identificador (ej: "analisis:rendimiento")
        *args, **kwargs: Par√°metros que afectan el resultado

    Returns:
        Clave de cach√© en formato "prefix:hash"
    """
    # Crear string √∫nico con todos los par√°metros
    params_str = json.dumps([args, sorted(kwargs.items())], sort_keys=True)
    params_hash = hashlib.md5(params_str.encode()).hexdigest()[:8]
    return f"{prefix}:{params_hash}"


async def get_cached(key: str) -> Optional[Any]:
    """
    Obtener valor del cach√©.

    Args:
        key: Clave de cach√©

    Returns:
        Valor deserializado o None si no existe
    """
    if not redis_client:
        return None

    try:
        value = await redis_client.get(key)
        if value:
            return json.loads(value)
    except Exception as e:
        print(f"Error obteniendo cach√© {key}: {e}")

    return None


async def set_cached(key: str, value: Any, ttl: int = None) -> bool:
    """
    Guardar valor en cach√©.

    Args:
        key: Clave de cach√©
        value: Valor a cachear (debe ser serializable a JSON)
        ttl: Tiempo de vida en segundos (usa default si no se especifica)

    Returns:
        True si se guard√≥ exitosamente
    """
    if not redis_client:
        return False

    if ttl is None:
        ttl = settings.REDIS_TTL_DEFAULT

    try:
        serialized = json.dumps(value, default=str)
        await redis_client.setex(key, ttl, serialized)
        return True
    except Exception as e:
        print(f"Error guardando cach√© {key}: {e}")
        return False


async def delete_cached(pattern: str) -> int:
    """
    Eliminar claves de cach√© que coincidan con un patr√≥n.

    Args:
        pattern: Patr√≥n de Redis (ej: "user:123:*")

    Returns:
        N√∫mero de claves eliminadas
    """
    if not redis_client:
        return 0

    try:
        keys = await redis_client.keys(pattern)
        if keys:
            return await redis_client.delete(*keys)
    except Exception as e:
        print(f"Error eliminando cach√© {pattern}: {e}")

    return 0


def cached_endpoint(prefix: str, ttl: int = None):
    """
    Decorador para cachear respuestas de endpoints.

    Usage:
        @router.get("/data")
        @cached_endpoint("data", ttl=3600)
        async def get_data(user_id: int):
            ...

    Args:
        prefix: Prefijo para la clave de cach√©
        ttl: Tiempo de vida en segundos
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # Generar clave √∫nica basada en argumentos
            cache_key = generate_cache_key(prefix, *args, **kwargs)

            # Intentar obtener del cach√©
            cached_value = await get_cached(cache_key)
            if cached_value is not None:
                return cached_value

            # Ejecutar funci√≥n original
            result = await func(*args, **kwargs)

            # Guardar en cach√©
            await set_cached(cache_key, result, ttl)

            return result

        return wrapper
    return decorator


async def invalidate_user_cache(user_id: int):
    """
    Invalidar todo el cach√© relacionado con un usuario.

    Args:
        user_id: ID del usuario
    """
    patterns = [
        f"analisis:*:user:{user_id}:*",
        f"habitos:user:{user_id}:*",
        f"registros:user:{user_id}:*",
    ]

    for pattern in patterns:
        deleted = await delete_cached(pattern)
        if deleted > 0:
            print(f"Invalidadas {deleted} claves de cach√©: {pattern}")
```

---

### Paso 5: Integrar Redis en el Ciclo de Vida de FastAPI

Editar `backend/app/main.py`, a√±adir despu√©s de la l√≠nea 30 (despu√©s de `create_tables()`):

```python
from .cache import init_redis, close_redis

@app.on_event("startup")
async def startup():
    await create_tables()
    await init_redis()  # üëà Nuevo

@app.on_event("shutdown")
async def shutdown():
    await close_redis()  # üëà Nuevo
```

---

### Paso 6: Implementar Cach√© en Endpoints

#### 6.1. An√°lisis de Rendimiento

Editar `backend/app/routers/analisis.py`, a√±adir import al inicio:

```python
from ..cache import cached_endpoint, invalidate_user_cache
from ..config import get_settings

settings = get_settings()
```

Modificar el endpoint de rendimiento (l√≠nea 23):

```python
@router.get("/rendimiento")
@cached_endpoint(
    prefix="analisis:rendimiento",
    ttl=settings.REDIS_TTL_ANALYTICS
)
async def obtener_analisis_rendimiento(
    fecha_inicio: str,
    fecha_fin: str,
    db: AsyncSession = Depends(get_db),
    current_user: Usuario = Depends(get_current_user)
):
    """
    An√°lisis de rendimiento diario en un rango de fechas.

    CACHEABLE: Resultados se cachean por 1 hora.
    """
    # ... c√≥digo existente sin cambios ...
```

#### 6.2. An√°lisis de Cumplimiento

Modificar el endpoint de cumplimiento (l√≠nea 89):

```python
@router.get("/cumplimiento")
@cached_endpoint(
    prefix="analisis:cumplimiento",
    ttl=settings.REDIS_TTL_ANALYTICS
)
async def obtener_analisis_cumplimiento(
    fecha_inicio: str,
    fecha_fin: str,
    db: AsyncSession = Depends(get_db),
    current_user: Usuario = Depends(get_current_user)
):
    """
    An√°lisis de cumplimiento por h√°bito.

    CACHEABLE: Resultados se cachean por 1 hora.
    """
    # ... c√≥digo existente sin cambios ...
```

#### 6.3. Listado de Categor√≠as

Editar `backend/app/routers/categorias.py`:

```python
from ..cache import cached_endpoint
from ..config import get_settings

settings = get_settings()

@router.get("/")
@cached_endpoint(
    prefix="categorias:list",
    ttl=settings.REDIS_TTL_CATEGORIES
)
async def obtener_categorias(
    db: AsyncSession = Depends(get_db),
    current_user: Usuario = Depends(get_current_user)
):
    """Listar todas las categor√≠as disponibles."""
    # ... c√≥digo existente sin cambios ...
```

#### 6.4. Listado de H√°bitos

Editar `backend/app/routers/habitos.py`:

```python
from ..cache import cached_endpoint, invalidate_user_cache
from ..config import get_settings

settings = get_settings()

@router.get("/")
@cached_endpoint(
    prefix="habitos:list",
    ttl=settings.REDIS_TTL_HABITS
)
async def obtener_habitos(
    db: AsyncSession = Depends(get_db),
    current_user: Usuario = Depends(get_current_user)
):
    """Obtener todos los h√°bitos del usuario."""
    # ... c√≥digo existente sin cambios ...
```

---

### Paso 7: Invalidaci√≥n de Cach√©

Para mantener los datos actualizados, debemos invalidar el cach√© cuando se crean/actualizan/eliminan datos.

#### 7.1. Invalidar al Crear H√°bito

En `backend/app/routers/habitos.py`, endpoint de creaci√≥n (l√≠nea ~40):

```python
@router.post("/", response_model=HabitoRead)
async def crear_habito(
    habito: HabitoCreate,
    db: AsyncSession = Depends(get_db),
    current_user: Usuario = Depends(get_current_user)
):
    """Crear un nuevo h√°bito."""
    # ... c√≥digo existente de creaci√≥n ...

    # Invalidar cach√© del usuario
    await invalidate_user_cache(current_user.id)  # üëà Nuevo

    return db_habito
```

#### 7.2. Invalidar al Actualizar H√°bito

En el endpoint de actualizaci√≥n (l√≠nea ~70):

```python
@router.put("/{habito_id}", response_model=HabitoRead)
async def actualizar_habito(
    habito_id: int,
    habito_update: HabitoUpdate,
    db: AsyncSession = Depends(get_db),
    current_user: Usuario = Depends(get_current_user)
):
    """Actualizar un h√°bito existente."""
    # ... c√≥digo existente de actualizaci√≥n ...

    # Invalidar cach√© del usuario
    await invalidate_user_cache(current_user.id)  # üëà Nuevo

    return db_habito
```

#### 7.3. Invalidar al Eliminar H√°bito

En el endpoint de eliminaci√≥n (l√≠nea ~100):

```python
@router.delete("/{habito_id}")
async def eliminar_habito(
    habito_id: int,
    db: AsyncSession = Depends(get_db),
    current_user: Usuario = Depends(get_current_user)
):
    """Eliminar un h√°bito."""
    # ... c√≥digo existente de eliminaci√≥n ...

    # Invalidar cach√© del usuario
    await invalidate_user_cache(current_user.id)  # üëà Nuevo

    return {"message": "H√°bito eliminado"}
```

#### 7.4. Invalidar al Registrar Progreso

En `backend/app/routers/registros.py`, cuando se actualiza progreso:

```python
from ..cache import invalidate_user_cache

# Despu√©s de actualizar progreso
await invalidate_user_cache(current_user.id)
```

---

### Paso 8: Testing

#### 8.1. Verificar Conexi√≥n

Crear `backend/test_redis.py`:

```python
"""Script de prueba para verificar conexi√≥n a Redis."""
import asyncio
from app.cache import init_redis, set_cached, get_cached, delete_cached

async def test_redis():
    print("Inicializando Redis...")
    await init_redis()

    # Test 1: Set y Get
    print("\n1. Test Set/Get")
    key = "test:simple"
    value = {"message": "Hello Redis"}

    success = await set_cached(key, value, ttl=60)
    print(f"   Set: {success}")

    cached = await get_cached(key)
    print(f"   Get: {cached}")
    assert cached == value, "Valor no coincide"

    # Test 2: Delete
    print("\n2. Test Delete")
    deleted = await delete_cached("test:*")
    print(f"   Deleted: {deleted} keys")

    cached = await get_cached(key)
    print(f"   Get after delete: {cached}")
    assert cached is None, "Clave deber√≠a estar eliminada"

    print("\n‚úÖ Todos los tests pasaron")

if __name__ == "__main__":
    asyncio.run(test_redis())
```

Ejecutar:
```bash
cd backend
python test_redis.py
```

#### 8.2. Verificar Endpoints Cacheados

```bash
# Terminal 1: Iniciar servidor
cd backend
uvicorn app.main:app --reload

# Terminal 2: Hacer request al endpoint de an√°lisis
curl -X GET "http://localhost:8000/api/analisis/rendimiento?fecha_inicio=2025-01-01&fecha_fin=2025-01-31" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN" \
  -w "\nTime: %{time_total}s\n"

# Primera request: ~200-500ms (sin cach√©)
# Segunda request: ~10-50ms (con cach√©)
```

#### 8.3. Monitorear Redis

```bash
# Ver todas las claves
redis-cli KEYS "*"

# Ver valor de una clave
redis-cli GET "analisis:rendimiento:abc123"

# Ver TTL de una clave
redis-cli TTL "analisis:rendimiento:abc123"

# Limpiar todo el cach√©
redis-cli FLUSHDB
```

---

## Estructura de Claves de Cach√©

```
analisis:rendimiento:{hash}      # TTL: 1 hora
analisis:cumplimiento:{hash}     # TTL: 1 hora
categorias:list:{hash}           # TTL: 24 horas
habitos:list:{hash}              # TTL: 15 minutos
habitos:user:{user_id}:*         # Patr√≥n para invalidaci√≥n
```

---

## Configuraci√≥n de Producci√≥n

### Docker Compose

Crear `docker-compose.yml` en la ra√≠z:

```yaml
version: '3.8'

services:
  redis:
    image: redis:7-alpine
    container_name: marco-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-changeme}
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  backend:
    build: ./backend
    container_name: marco-backend
    ports:
      - "8000:8000"
    environment:
      - REDIS_URL=redis://:${REDIS_PASSWORD:-changeme}@redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped

volumes:
  redis_data:
```

### Variables de Entorno Producci√≥n

```bash
# .env.production
REDIS_URL=redis://:strong_password_here@redis:6379/0
REDIS_TTL_ANALYTICS=3600
REDIS_ENABLED=true
```

---

## M√©tricas y Monitoreo

### Endpoint de Health Check

A√±adir a `backend/app/main.py`:

```python
from .cache import redis_client

@app.get("/health")
async def health_check():
    """Health check incluyendo estado de Redis."""
    redis_status = "disconnected"

    if redis_client:
        try:
            await redis_client.ping()
            redis_status = "connected"
        except:
            redis_status = "error"

    return {
        "status": "ok",
        "redis": redis_status,
        "timestamp": datetime.now().isoformat()
    }
```

### Estad√≠sticas de Cach√©

Crear endpoint de admin para ver estad√≠sticas:

```python
@router.get("/admin/cache/stats")
async def cache_stats(
    current_user: Usuario = Depends(get_current_user)
):
    """Ver estad√≠sticas de Redis (solo admin)."""
    if redis_client:
        info = await redis_client.info()
        return {
            "keys": await redis_client.dbsize(),
            "memory": info.get("used_memory_human"),
            "hits": info.get("keyspace_hits"),
            "misses": info.get("keyspace_misses"),
        }
    return {"error": "Redis not available"}
```

---

## Troubleshooting

### Error: "Connection refused"

```bash
# Verificar que Redis est√© corriendo
redis-cli ping

# Si no responde, iniciar Redis
redis-server
```

### Error: "Module not found: redis"

```bash
cd backend
uv sync
```

### Cach√© no se invalida correctamente

```bash
# Limpiar todo el cach√© manualmente
redis-cli FLUSHDB

# Ver logs del backend
uvicorn app.main:app --reload --log-level debug
```

### Performance no mejora

1. Verificar que `REDIS_ENABLED=true`
2. Verificar que los decoradores `@cached_endpoint` est√©n aplicados
3. Hacer m√∫ltiples requests al mismo endpoint con los mismos par√°metros
4. Monitorear con `redis-cli MONITOR`

---

## Pr√≥ximos Pasos (Opcional)

### 1. Cach√© de Sesiones JWT
Almacenar tokens invalidados en Redis para logout global.

### 2. Rate Limiting
Usar Redis para limitar requests por usuario/IP.

### 3. Pub/Sub para Notificaciones
Implementar notificaciones en tiempo real.

### 4. Redis Sentinel/Cluster
Alta disponibilidad en producci√≥n.

---

## Referencias

- [Redis Python Docs](https://redis.readthedocs.io/en/stable/)
- [FastAPI Async Background Tasks](https://fastapi.tiangolo.com/tutorial/background-tasks/)
- [Redis Best Practices](https://redis.io/docs/manual/patterns/)

---

## Checklist de Implementaci√≥n

- [ ] Instalar Redis
- [ ] Agregar dependencia `redis>=5.0.0`
- [ ] Actualizar `config.py` con settings de Redis
- [ ] Crear `cache.py` con funciones helper
- [ ] Integrar en lifecycle de FastAPI (`main.py`)
- [ ] Aplicar decorador `@cached_endpoint` en an√°lisis
- [ ] Aplicar decorador en categor√≠as
- [ ] Aplicar decorador en h√°bitos
- [ ] Implementar invalidaci√≥n en creates/updates/deletes
- [ ] Ejecutar `test_redis.py`
- [ ] Verificar mejora de performance
- [ ] Documentar en README.md
- [ ] Configurar para producci√≥n (Docker Compose)

---

**Tiempo estimado total:** 3-6 horas (desarrollo + testing + documentaci√≥n)

**Impacto esperado:** Reducci√≥n de 80-90% en tiempo de respuesta de endpoints de an√°lisis.